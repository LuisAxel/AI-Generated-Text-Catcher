{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef129964-3985-4dcd-b856-566e983c9237",
   "metadata": {},
   "source": [
    "# Text clasification with DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6177d2ad-e8ce-41a8-b342-b79b32bf3f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisaxel/Desktop/repos/AI-Generated-Text-Catcher/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.4.0+cu121', '4.44.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "torch.__version__, transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab37e0b-0e9b-4fc4-99fb-c555e23e26c1",
   "metadata": {},
   "source": [
    "## 1.- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d45b77d-90e8-4720-b49c-f8b4678c6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ods file\n",
    "input_file = './data/processed.ods'\n",
    "df = pd.read_excel(input_file, engine=\"odf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f736ba6-aeb5-4580-91d5-a4966fa3e10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Jose in California 1903, Ms Winchester is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so they will make some business. So they look ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so she couldn’t own that house. After a while ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the mansion, also the ghost poseer the child o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that the ms winchester did in the past, or the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  San Jose in California 1903, Ms Winchester is ...      1\n",
       "1  so they will make some business. So they look ...      1\n",
       "2  so she couldn’t own that house. After a while ...      1\n",
       "3  the mansion, also the ghost poseer the child o...      1\n",
       "4  that the ms winchester did in the past, or the...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b92670-8608-44ed-b940-a86b38d6fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fbce0dd-4174-451d-aff8-2d6bb1d25583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    240\n",
       "1    230\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb28909-4cbc-40a9-be15-075509dcaf16",
   "metadata": {},
   "source": [
    "- Remove special characters and transform to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94327ccd-2c5a-4657-8872-58c8cf76780d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>san jose in california 1903 ms winchester is t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so they will make some business so they look f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so she couldn’t own that house after a while i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the mansion also the ghost poseer the child of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that the ms winchester did in the past or the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  san jose in california 1903 ms winchester is t...      1\n",
       "1  so they will make some business so they look f...      1\n",
       "2  so she couldn’t own that house after a while i...      1\n",
       "3  the mansion also the ghost poseer the child of...      1\n",
       "4  that the ms winchester did in the past or the ...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation\n",
    "df['text'] = df['text'].str.lower().str.translate(str.maketrans('', '', string.punctuation))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27be14-5730-477e-830d-1a381eb8988f",
   "metadata": {},
   "source": [
    "## 2.- Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3676d44b-b644-446f-9f40-51823a645344",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "batch_size = 4\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb084bc-8526-46cc-81a2-03025e8c436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.label.astype(float)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d62705-8045-450d-88b4-7c04dacf9ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 70)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 0.85\n",
    "train_data = df.sample(frac=train_size,random_state=123)\n",
    "test_data = df.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "train_data = LabelDataset(train_data, tokenizer, maxlen)\n",
    "test_data = LabelDataset(test_data, tokenizer, maxlen)\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de6dae0e-eef8-4e34-b84b-6a33629acc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': batch_size,\n",
    "               'num_workers': 0\n",
    "               }\n",
    "\n",
    "train_loader = DataLoader(train_data, **train_params)\n",
    "test_loader = DataLoader(test_data, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84745acb-6d82-48cb-8b2d-cb8c9cfea631",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900e37c2-8afc-4fe3-a928-425e17f00e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[  101,  2001,  1037,  8987,  2214, 10276,  2315,  2002,  6593,  7076,\n",
       "           2040,  2018,  2042,  1996,  4602,  1997,  2010,  2051,  2588,   102],\n",
       "         [  101,  1059, 27511,  1037,  2711,  1999,  1996,  2277,  2061,  2023,\n",
       "           2711,  2202,  1996, 10658,  1999,  2014,  2482,  1998,  2175,   102],\n",
       "         [  101,  1998,  2010,  3129,  3419,  2020,  1999,  1996,  2160,  2021,\n",
       "           3419,  2404,  1996, 10658,  9617, 25766,  1999,  1996, 11669,   102],\n",
       "         [  101,  1996,  6138,  1999,  2047,  5979,  5255,  2068,  2000,  1996,\n",
       "           2598,  2021,  5573, 18718,  2726,  1996,  9191, 13555,  2008,   102]]),\n",
       " 'mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'targets': tensor([0., 1., 1., 1.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b34d0d-f8e6-4b0d-8f27-064ba10eb1db",
   "metadata": {},
   "source": [
    "## 3.- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ebd5de-204b-4bc7-bd8a-6bb9e837935e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5141],\n",
       "        [0.4925],\n",
       "        [0.5205],\n",
       "        [0.4946]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DistilBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistilBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.classifier = torch.nn.Linear(768, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "ids = train_batch['ids']\n",
    "mask = train_batch['mask']\n",
    "token_type_ids = train_batch['token_type_ids']\n",
    "targets = train_batch['targets']\n",
    "\n",
    "model = DistilBERTClass()\n",
    "outputs = model(ids, mask, token_type_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d11ccd8-3523-46fe-9759-6cff6e52f5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7507855d-28c6-475c-bb0e-9840935c8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "lr = 1e-05\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e76122-6893-4580-98d9-a691a2635df7",
   "metadata": {},
   "source": [
    "## 4.- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "747db2e8-eb75-472e-a1e9-e8e5b25d0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    start = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in test_loader:\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            token_type_ids = data['token_type_ids'].to(device)\n",
    "            labels = data['targets'].to(device)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            outputs = outputs.squeeze()\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.round()  # Round the outputs to get predicted labels\n",
    "            running_acc += (preds == labels).sum().item()  # Compute number of correct predictions\n",
    "\n",
    "    val_acc = running_acc / len(test_loader.dataset)\n",
    "    print(f'Time for eval is {time.time()-start:.4f} sec Val loss: {running_loss / len(test_loader):.4f}')\n",
    "    print(f'Val acc: {val_acc:.4f}')\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec9a99c0-01cb-4129-b47e-99b78f48b041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40f333db-97e0-490e-95eb-ccf98d10945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, test_loader, interval=300):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for _, data in tqdm(enumerate(train_loader, 0)):\n",
    "        ids = data['ids'].to(device)\n",
    "        mask = data['mask'].to(device)\n",
    "        token_type_ids = data['token_type_ids'].to(device)\n",
    "        labels = data['targets'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        outputs = outputs.squeeze()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if _ % interval == 0:\n",
    "            print(f'Train loss: {loss.item():.4f}')\n",
    "            val_acc = test(model, device, test_loader)\n",
    "            if val_acc > 0.85:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "756fdd09-aab5-44c0-83dc-c3a2c6fd3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4abc5ec2-9cbf-4991-80fc-56b6653ebbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 15.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7233\n",
      "Time for eval is 0.0833 sec Val loss: 0.6998\n",
      "Val acc: 0.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:03, 31.68it/s]\n",
      "5it [00:00, 24.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8817\n",
      "Time for eval is 0.0754 sec Val loss: 0.5700\n",
      "Val acc: 0.6286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:02, 33.51it/s]\n",
      "2it [00:00, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0399\n",
      "Time for eval is 0.0635 sec Val loss: 0.3889\n",
      "Val acc: 0.8286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:02, 33.61it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0283\n",
      "Time for eval is 0.0591 sec Val loss: 0.4159\n",
      "Val acc: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1276\n",
      "Time for eval is 0.0633 sec Val loss: 0.4119\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0605 sec Val loss: 0.4086\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0634 sec Val loss: 0.4059\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0612 sec Val loss: 0.4039\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0620 sec Val loss: 0.4023\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0707 sec Val loss: 0.4015\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0605 sec Val loss: 0.4008\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0598 sec Val loss: 0.4004\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0621 sec Val loss: 0.4002\n",
      "Val acc: 0.8857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0608 sec Val loss: 0.4008\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0628 sec Val loss: 0.4015\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0605 sec Val loss: 0.4036\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0602 sec Val loss: 0.4044\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0658 sec Val loss: 0.4055\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0624 sec Val loss: 0.4074\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for eval is 0.0615 sec Val loss: 0.4093\n",
      "Val acc: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train(epoch, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf3eb12e-bb38-47b2-a6c6-032a5e326314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_text(text: str, segment_length: int = 20) -> list:\n",
    "    words = text.split()\n",
    "    segments = [(' '.join(words[i:i + segment_length])) \n",
    "                for i in range(0, len(words), segment_length)]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71e7dbe2-8518-46bd-8cb9-a5b621dc8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_essay(essay, model, tokenizer, max_len, device):\n",
    "    chunks = segment_text(essay)\n",
    "\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Tokenize and prepare the chunk\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            chunk,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        ids = torch.tensor(inputs['input_ids'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            outputs = outputs.squeeze()\n",
    "\n",
    "        predicted_prob = outputs\n",
    "        all_predictions.append(predicted_prob)\n",
    "\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d2cd3ec-86c6-43aa-b91a-f3b78dc5cedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9914416670799255, 0.5460850596427917, 0.9470161199569702, 0.9765793085098267, 0.9852501749992371, 0.9841912984848022, 0.9848730564117432, 0.9324618577957153, 0.9784491062164307, 0.8833802342414856, 0.9639078974723816, 0.4878084659576416, 0.5620577335357666, 0.971889317035675]\n",
      "Predicted percentage: 87.11%\n"
     ]
    }
   ],
   "source": [
    "essay = \"\"\"They Kicked the boy out of his band and since it was the only thing he had as a job he was forced to look for a job in a school but he had no other speciality tan music so he had to pretend to be a math/sience teacher So he could work as a \"teacher”. One day he saw that his students played instruments so well, and that's where it started all Would he prefer to teach them math/sience or music? After posing as a teacher and seeng how well his students played music, he decided to descover each one ability, literally this kids can play rock music.Maybe he thought “If they kicked me out of of the band I was in, why don't I make my own band\"? Or maybe he just did it because music was his passion. But he has to continue keeping the secret were they going to find out what he did? what would happen if they did? The students were confused out first, but then they started to like it and with their imagination and ideas they create some Incredible things, each one has incredible qualities that can be seen during the movie, that \"teacher\" was crazy!! and everything is going well until... of course there has to be a problem, I think he didn't fully think about what parents say, or what EVERYONE Would say when they discovered what he was hiding. But when they demonstrated their talent a stage after secretly entering to on a a competition, the parents realized their children talent and had no problems.\"\"\"\n",
    "pred = test_essay(essay, model, tokenizer, maxlen, device)\n",
    "print([tensor.item() for tensor in pred])\n",
    "\n",
    "average_prediction = sum(pred) / len(pred)\n",
    "percentage = average_prediction * 100\n",
    "print(f\"Predicted percentage: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb4611a-f57f-42f3-8be0-8d0668d92e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ad7ce-a93c-4866-9793-52256f1691fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./models/', exist_ok=True)\n",
    "output_model_file = './models/pytorch_distilbert_writings.bin'\n",
    "output_vocab_file = './models/vocab_distilbert_writings.bin'\n",
    "\n",
    "torch.save(model, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
